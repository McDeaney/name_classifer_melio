# Melio Data Science Interview (with Highwind)

## Full Name Classifier Assignment

You received a dataset from your client containing a list of names and their potential classifications. Your client asks you to build a basic Web based HTTP API that their own frontend application can integrate with. The client's frontend application will send a request containing a user's Full Name and your API will return the classification of the name.

Your task is to build a basic end-to-end machine learning system that allows the following:

  1. An API that returns the classification of the name, either `Person`, `Company` or `University`

     - The logic of the classification can be a rule-based or machine learning classifier 

     - The backend must be a web service that provides an HTTP API

  2. The API backend must be hosted on [Highwind](https://docs.highwind.ai):

     - Highwind uses [KServe v0.10](https://kserve.github.io/website/0.10/) for model serving, which means your model needs to support Kserve.
       - An overview of model deployment on Highwind can be found here: https://docs.highwind.ai/zindi/deploy/.
       - An extensive tutorial on how to deploy a model on Highwind can be found here: https://docs.highwind.ai/tutorials/deploy-custom/. 

An example of the user workflow is as follows:

  1. User makes a request containing `Bob Immerman` to the Highwind API.
  2. The API classifies Bob and returns the classification as `Person`.

## Task Details

There are three main tasks in the problem, and as the consultant, you can decide on the relative importance of each:

  1. Building the classifier
  2. Model inference server (via Kserve) as an API
  3. Hosting the model on Highwind

You should limit yourself to 4 hours, and make tradeoffs based on the allotted timeframe.

### Task 1: Building the classifier

This is the main data science component of the technical assessment.

Build a classifier to determine whether the name belongs to a `Person`, `Company`, or `University`:

- You can use any library you want.
- You can use a rule-based classification, a pre-built model/embedding, build a model yourself or a hybrid.
- Format:
  - If you are building an ML solution, the training of your model can be in a Jupyter notebook.
  - If you are not building an ML solution, you will have to embed your Python code into the app.

Note that the classifications are generated by the client's upstream system, but they are not always correct. 

**Task 1 Evaluation Criteria:** Your classifier will be evaluated based on a hidden test set.

### Task 2: Inference Server (via Kserve)

This task evaluates whether you understand what is involved in putting a classifier into production.

Build an inference server that accepts a string as an input and returns the classification, adhering to the JSON format that Kserve accepts.

- You can use any framework that can be served via Docker.
- You do not need to build a database component.
- Format:
  - The model is contained in a Docker image following: https://docs.highwind.ai/tutorials/deploy-custom/.
  - The model is exposed via the Kserve API following: https://docs.highwind.ai/tutorials/deploy-custom/.
    - Here is a provided example on how to build a deployment docker image: https://github.com/highwind-ai/examples/tree/main/translate-dyu-fr-hugging-face/deployment

**Task 2 Success Criteria:** Your inference server API is accessible and can respond with the appropriate classification based on the input.

### Task 3: Model Hosting on Highwind

Deploy your model on Highwind. This includes creating the associated Asset and then deploying it as a Use Case. After a successful deployment in your Use Case, you should be able to see this image below:

![Successful Deployment](./images/success-deployment.png)

You can then test if your inference API is working by using the Hosted Inference API section in the Use Case:

![Hosted Inference API](./images/hosted-inference-api.png)

Considerations:
1. The deployed model must adhere to the following hardware restrictions (or the deployment will fail):
   1. CPU: Not more than 1 vCPU
   2. Memory: Not more than 2GB RAM
   3. Docker Image Size: Less than 6GB

**Task 3 Success Criteria:** Your deployed model on Highwind is able to receive requests and respond appropriately.

## Overall Evaluation Criteria:

  1. Write a brief summary to critically evaluate your solution.
  - Solutiton uses spacy NER and a custom pipeline to recognise entities.
  - Since the dat wasnt clean I adjusted the dataset to use a cleaner version by running the NER pipeline to see which entities may be inccorectly lablled
  - The result was dropping all the rows the NER was unsure of. Here maybe should mannually clean up dataset. Used large model trf for this.
  - The clean dataset was used to test. 
  - The imbalanced data classes required oversampling after attempting this chose to go with another idea.
  - The pipeline consists of spacy classifier (eng_md) firstly determining whether person or organisation.
  - The additional step in the pipeline is to classify org into university or company.
  - The subcategory was classified via rule based and keyword system. 
  - The results are as follows:
      - Entity Type Accuracy: 0.8735


|   |  precision  | recall  |  f1-score | support  |
|---|---|---|---|---|
|  ORG |  0.58 | 0.81  |  0.68  | 569  |
|   PERSON |  0.98   |  0.88    | 0.93  |  3455  |
    
  - Organization Subtype Accuracy: 0.3726

|   |   precision | recall   |  f1-score | support  |
|---|---|---|---|---|
|  COMPANY   |  0.93    |  0.34   |  0.50  | 473  |
|  UNIVERSITY  | 0.78   | 0.52  |  0.62  |   96 |
 
  - For the api using kserve had to adjust dockerfile and some of the inheherited code from kserve.
  - Works locally
  - Cant deploy on highwind getting 403 error when psuhing up to repo, even though login successful                      
  - To improve model could use larger spacy trf model in pipeline otherwise a larger dataset on universities to reatrain using transfer learning
  - 

  2. You should limit yourself to 4 hours, and make tradeoffs based on the allotted timeframe.
  - Tradeoff taken in deployment couldnt push image for task 3 got 403 forrbidden
  - Spent most time expirementing on NER data science part. To get a baseline and ideas to solve problem

  3. There is no right or wrong answer, but give a clear reasoning on each step you took. 

## Submission Requirements

  1. Give enough information on how to run your solution (i.e., Python version, packages, requirements.txt, Dockerfile, etc.).
  - Python version 3.12.3 
  - To run notebook: 
    - Create virtual environment 
    - Install requirremnts.txt file inside notebooks folder.
    - run notebook topdown
  - To run local depolyment:
    - build docker image in deployments folder
    - docker build -t local/highwind/my-model .
    - docker compose up the compose file
    - curl payload to server
    - curl -X POST http://localhost:8080/v2/models/modelLOL/infer -H 'Content-Type: application/json' -d @./payload.json 

  2. State all of your assumptions, if any.
    - Assuming the language is english and only one entity in text. 

  3. There is no right or wrong answer, but give a clear reasoning on each step you took. 
  4. You can zip your code and email it to your hiring manager, or you can push it onto GitHub and let your hiring manager know.

## Dataset

**Note:** The dataset for this assignment should be provided to you separately by your hiring manager. If you haven't received it, please contact them.
